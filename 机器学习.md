## 〇.介绍
1. 学习导图
  - 监督学习(Supervised Learning)
    - 回归问题Regression ：输出数值
    - 分类问题Classification ：预测二分类，多分类问题
      - 线性模型
      - 非线性模型
        - 深度学习
        - 支持向量机SVM
        - 决策树
        - 邻近算法K-NN
        - ...
    - 结构化问题Structured Learning
      - 在实际运用中，常常会遇到Beyond Classification的情况，比如语音识别，人脸识别，语言翻译等，是结构化输出。此类问题常合Reinforcement Learning 解决
  - 半监督学习
  - 迁移学习
  - 无监督学习
  - 强化学习Reinforcement Learning
    - 思考：监督学习和强化学习的区别
2. 模型评估和选择
  - 传统机器学习的回顾
    - 人工智能是一个非常大的概念，而机器学习只是人工智能的一种实现方法。深度学习是同样也是一种实现机器学习的方法，是在机器学习的基础上建立起来的。这体现在，首先从字面上看，二者都是在“学习”，因此在评价深度学习训练出的模型好坏时，同样直接来源于机器学习的评价方法。其次，深度学习最常见的形式，深度神经网络，直接脱胎于机器学习中的神经网络模型。
  - 机器学习的评估方法
      - 留出法：
        - 将数据集D划分为两个互斥的集合训练集S和测试集T，在S上训练出模型后，用T来评估其测试误差。一般使用大约2/3~4/5的样本用于训练，剩余样本用于测试
      - 交叉检验法(k折交叉检验)：
        - 将数据集D划分为K个大小相似的互斥子集，每次用k-1个子集的并集做训练集，余下的那个子集作为测试集，从而可进行k次训练和测试，最后返回k个测试结果的均值
        - k最常的取值是10，其他常用的k值为5，20
      - 自助法
        - 以自助采样为基础，自助法在数据集较小，难以有效划分训练/测试集时很有用
  - 性能度量指标
      - 错误率errorrate和精度accuracy
        - 错误率：分类错误的样本占样本总数的比例
        - 精度： 1-错误率
      - 准确率Precision、召回率recall、F1
        - P=TP/(TP+FP) R=TP/(TP+FN)
        - PR图 : 可直观显示出学习器在样本总体上的准确率和召回率
        - 平衡点BEP（break-Even Point）： P=R时的取值，BEP越高，学习器效果越好
        - F1度量：F1 = (2*P*R)/(P+R)
      - ROC曲线和AUC
        - 二分类问题在机器学习中是一个很常见的问题。ROC(Receiver Operating Characteristic) 曲线和 AUC (Area Under the Curve) 值常被用来评价一个二值分类器 (binary classifier) 的优劣。
        - ROC：
          - ROC曲线：接收者操作特征曲线(receiver operating characteristic curve)，是反映敏感性和特异性连续变量的综合指标，roc曲线上每个点反映着对同一信号刺激的感受性。
          - ROC曲线纵轴是TPR（真正例律），横纵是FPR(假正例率)
          - 分类器的一个重要功能“概率输出”，即表示分类器认为某个样本具有多大的概率属于正样本（或负样本）。通过更深入地了解各个分类器的内部机理，我们总能想办法得到一种概率输出。通常来说，是将一个实数范围通过某个变换映射到(0,1)区间。
        - AUC
          - AUC (Area Under Curve) 被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围一般在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。
          - AUC的计算有两种方式，梯形法和ROC AUCH法，都是以逼近法求近似值，具体见wikipedia。
          - 根据(Fawcett, 2006)，AUC的值的含义是：The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.首先AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。
          - AUC判断分类器（预测模型）优劣的标准：AUC值越大的分类器，正确率越高。
            - AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。
            - 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
            - AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
            - AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。
        - 为什么要使用ROC和AUC？
          - 因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡(class imbalance)现象，即负样本比正样本多很多(或者相反)，而且测试数据中的正负样本的分布也可能随着时间变化。
      - 潜在问题：欠拟合和过拟合
        - 如何避免？分成三个部分，一部分作为 训练集，一部分作为验证集，最后还有 测试集
    - 机器学习的模型实现（提高深度学习模型预测的准确性）
      - 调整模型的参数，无疑是最简单最快速的方法，但调参并不能从根本上解决分类准确性的问题。如果是数据 欠拟合，则通常需要更多的特征、更优化的模型。
